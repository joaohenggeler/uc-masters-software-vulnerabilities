#!/usr/bin/env python3

"""
	Exports the most relevant values from a given Propheticus results comparison Excel log to a CSV file. Also shows
	the best results for each label and performance metric.

	Before passing the Excel file to this script, it must be first generated by running the experiments in Propheticus
	and then telling it to compare all results.
"""

from argparse import ArgumentParser

import pandas as pd # type: ignore

from modules.common import log, replace_in_filename

####################################################################################################

parser = ArgumentParser(description='Exports the most relevant values from a given Propheticus results comparison Excel log file.')
parser.add_argument('input_excel_path', help='The path to the Excel results log file.')
args = parser.parse_args()

output_csv_path = replace_in_filename(args.input_excel_path, '.xlsx', '.csv')
log.info(f'Exporting results from "{args.input_excel_path}" to "{output_csv_path}".')

results = pd.read_excel(args.input_excel_path, sheet_name='Report', usecols='B:C,H:K,N,U:V', skiprows=5)

metric_list = ['Precision', 'Recall', 'F1-Score']
best_output_columns = [	'Experiment', 'Algorithm', 'proc_balance_data',
						'proc_classification_algorithms_parameters',
						'proc_reduce_dimensionality'] + metric_list

separator = '########################################################################################################################'

for label in results['pre_target'].unique():
	for metric in metric_list:
	
		is_label = (results['pre_target'] == label)
		label_results_for_metric = results.loc[is_label, metric]
		is_best_for_label = (label_results_for_metric == label_results_for_metric.max())
		best_results = results[is_label].loc[is_best_for_label, best_output_columns]
		
		log.info(f'Found {is_best_for_label.sum()} best {metric} results for {label}:\n{separator}\n{best_results.to_string()}\n{separator}')

results.rename(	columns={
							'pre_target': 'Target Label',
							'proc_balance_data': 'Data Balancing',
							'proc_classification_algorithms_parameters': 'Algorithm Parameters',
							'proc_reduce_dimensionality': 'Dimensionality Reduction',
							'F1-Score': 'F-Score',
						},
				inplace=True)

results.to_csv(output_csv_path, index=False)

log.info('Finished running.')
print('Finished running.')