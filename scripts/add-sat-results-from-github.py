#!/usr/bin/env python
import base64
import os
import re
import sys
import zipfile

import mysql.connector
import numpy as np
import pandas as pd
from github import Github

import estagio

"""
	This script adds the contents of any files that were generated by SATs (Cppcheck, Flawfinder, etc) to four different tables in
	the database: 'sat', 'rule', 'rule_cwe_info', 'alert'. These files are downloaded from a private GitHub repository before
	being decompressed and loaded into the database.

	The 'cwe_info' table currently does not need to be created before running this script.

	Requirements:

	pip install mysql-connector-python
	pip install numpy
	pip install pandas
	pip install PyGithub
"""

DEBUG_MODE = True
if DEBUG_MODE:
	print('Debug mode is enabled!')

database_config = estagio.load_database_config()

try:
	print('Connecting to the database...')
	connection = mysql.connector.connect(**database_config)
	cursor = connection.cursor(prepared=True)
except mysql.connector.Error as error:
	error_string = repr(error)
	print(f'Failed to connect to the database with the error: {error_string}')
	sys.exit(1)

# --------------------------------------------------

if DEBUG_MODE:

	try:
		print('Dropping all SAT related tables...')
		cursor.execute(	'''
							DROP TABLE IF EXISTS sat, rule, rule_cwe_info, alert;
						''')

		connection.commit()
	except mysql.connector.Error as error:
		error_string = repr(error)
		print(f'Failed to drop all SAT related tables with the error: {error_string}')
		sys.exit(1)

# --------------------------------------------------

try:
	print('Creating the SAT table...')
	cursor.execute(	'''
						CREATE TABLE IF NOT EXISTS sat
						(
							SAT_ID INTEGER AUTO_INCREMENT PRIMARY KEY,
							SAT_NAME VARCHAR(50) NOT NULL UNIQUE
						);
					''')

	connection.commit()
except mysql.connector.Error as error:
	error_string = repr(error)
	print(f'Failed to create the SAT table with the error: {error_string}')
	sys.exit(1)

# --------------------------------------------------

try:
	print('Creating the Rules table...')
	cursor.execute(	'''
						CREATE TABLE IF NOT EXISTS rule
						(
							RULE_ID INTEGER AUTO_INCREMENT PRIMARY KEY,
							RULE_NAME VARCHAR(100) NOT NULL,
							RULE_CATEGORY VARCHAR(50) NOT NULL,

							SAT_ID INTEGER NOT NULL,

							UNIQUE KEY (RULE_NAME, SAT_ID),
							
							FOREIGN KEY (SAT_ID) REFERENCES sat(SAT_ID) ON DELETE RESTRICT ON UPDATE RESTRICT
						);
					''')

	connection.commit()
except mysql.connector.Error as error:
	error_string = repr(error)
	print(f'Failed to create the Rules table with the error: {error_string}')
	sys.exit(1)

# --------------------------------------------------

try:
	print('Creating the Rules to CWE Info table...')
	cursor.execute(	'''
						CREATE TABLE IF NOT EXISTS rule_cwe_info
						(
							RULE_ID INTEGER,
							V_CWE INTEGER,
							
							PRIMARY KEY (RULE_ID, V_CWE),

							FOREIGN KEY (RULE_ID) REFERENCES rule(RULE_ID) ON DELETE RESTRICT ON UPDATE RESTRICT
						);
					''')

	# For now, we'll remove this foreign key relationship since we would otherwise be unable to add CWE values
	# that don't already exist in the 'cwe_info' table.
	# FOREIGN KEY (V_CWE) REFERENCES cwe_info(V_CWE) ON DELETE RESTRICT ON UPDATE RESTRICT

	connection.commit()
except mysql.connector.Error as error:
	error_string = repr(error)
	print(f'Failed to create the Rules to CWE Info table with the error: {error_string}')
	sys.exit(1)

# --------------------------------------------------

try:
	print('Creating the Alerts table...')
	cursor.execute(	'''
						CREATE TABLE IF NOT EXISTS alert
						(
							ALERT_ID INTEGER AUTO_INCREMENT PRIMARY KEY,
							ALERT_SEVERITY_LEVEL INTEGER,
							ALERT_LINE INTEGER NOT NULL,
							ALERT_MESSAGE VARCHAR(1000),

							RULE_ID INTEGER NOT NULL,
							ID_File INTEGER NOT NULL,
							
							FOREIGN KEY (RULE_ID) REFERENCES rule(RULE_ID) ON DELETE RESTRICT ON UPDATE RESTRICT
						);
					''')

	connection.commit()
except mysql.connector.Error as error:
	error_string = repr(error)
	print(f'Failed to create the Alerts table with the error: {error_string}')
	sys.exit(1)

# --------------------------------------------------

def insert_rule_and_alert_into_database(cursor, index,
										sat_name, rule_name, rule_category, rule_cwe_list,
										alert_severity_level, alert_line, alert_message,
										alert_file_path, alert_file_occurrence, alert_file_commit):

	try:
		if DEBUG_MODE:
			print(f'-> Inserting the rule "{rule_name}"...')

		cursor.execute(	'''
							INSERT IGNORE INTO rule (RULE_NAME, RULE_CATEGORY, SAT_ID)
							VALUES
							(
								%s,
								%s,
								(SELECT SAT_ID FROM sat WHERE SAT_NAME = %s LIMIT 1)
							);
						''',
						(rule_name, rule_category, sat_name))

		connection.commit()
	except mysql.connector.Error as error:
		error_string = repr(error)
		print(f'- Failed to insert the rule "{rule_name}" with the error: {error_string}')

	try:
		rule_cwe_list = [(rule_name, sat_name, cwe) for cwe in cwe_list]

		if DEBUG_MODE and cwe_list:
			cwe_list_string = ', '.join(cwe_list)
			print(f'-> Inserting the CWEs: {cwe_list_string}...')

		cursor.executemany(	'''
								INSERT IGNORE INTO rule_cwe_info (RULE_ID, V_CWE)
								VALUES
								(
									(
										SELECT RULE_ID FROM rule
										WHERE RULE_NAME = %s AND SAT_ID = (SELECT SAT_ID FROM sat WHERE SAT_NAME = %s LIMIT 1)
										LIMIT 1
									),
									%s
								);
							''',
							rule_cwe_list)

		connection.commit()

	except mysql.connector.Error as error:
		error_string = repr(error)
		print(f'- Failed to insert the rule "{rule_name}" with the error: {error_string}')

	try:
		if DEBUG_MODE:
			print(f'-> Inserting the alert {index+1} from line {alert_line} in the file "{alert_file_path}"...')

		cursor.execute(	'''
							INSERT INTO alert (ALERT_SEVERITY_LEVEL, ALERT_LINE, ALERT_MESSAGE, RULE_ID, ID_File)
							VALUES
							(
								%s,
								%s,
								%s,
								(
									SELECT RULE_ID FROM rule
									WHERE RULE_NAME = %s AND SAT_ID = (SELECT SAT_ID FROM sat WHERE SAT_NAME = %s LIMIT 1)
									LIMIT 1
								),
								(
									SELECT f.ID_File FROM
									(
										SELECT ID_File FROM files_1_dom WHERE FilePath = %s AND Occurrence = %s
										UNION ALL
										SELECT ID_File FROM files_1_javascript WHERE FilePath = %s AND Occurrence = %s
										UNION ALL
										SELECT ID_File FROM files_1_javascript_extras WHERE FilePath = %s AND Occurrence = %s
										UNION ALL
										SELECT ID_File FROM files_1_javascript_xpconnect WHERE FilePath = %s AND Occurrence = %s
										UNION ALL
										SELECT ID_File FROM files_1_layout_rendering WHERE FilePath = %s AND Occurrence = %s
										UNION ALL
										SELECT ID_File FROM files_1_libraries WHERE FilePath = %s AND Occurrence = %s
										UNION ALL
										SELECT ID_File FROM files_1_mozilla WHERE FilePath = %s AND Occurrence = %s
										UNION ALL
										SELECT ID_File FROM files_1_network WHERE FilePath = %s AND Occurrence = %s
										UNION ALL
										SELECT ID_File FROM files_1_toolkit WHERE FilePath = %s AND Occurrence = %s
										UNION ALL
										SELECT ID_File FROM files_1_webpage_structure WHERE FilePath = %s AND Occurrence = %s
										UNION ALL
										SELECT ID_File FROM files_1_widget WHERE FilePath = %s AND Occurrence = %s
									) f
									INNER JOIN extra_time_files AS e ON f.ID_File = e.ID_File
									WHERE e.P_ID = (SELECT P_ID FROM patches WHERE P_COMMIT = %s LIMIT 1)
									LIMIT 1
								)
							);
						''',
						(alert_severity_level, alert_line, alert_message, rule_name, sat_name,
						alert_file_path, alert_file_occurrence,
						alert_file_path, alert_file_occurrence,
						alert_file_path, alert_file_occurrence,
						alert_file_path, alert_file_occurrence,
						alert_file_path, alert_file_occurrence,
						alert_file_path, alert_file_occurrence,
						alert_file_path, alert_file_occurrence,
						alert_file_path, alert_file_occurrence,
						alert_file_path, alert_file_occurrence,
						alert_file_path, alert_file_occurrence,
						alert_file_path, alert_file_occurrence,
						alert_file_commit))

		connection.commit()
	except mysql.connector.Error as error:
		error_string = repr(error)
		print(f'- Failed to insert the alert {index+1} with the error: {error_string}')

# --------------------------------------------------

print('Finding the SAT result files in the GitHub repository...')

github = Github('e8b607cb0e7b3722d57d7d2b8b0f586cffeb71de')
repository = github.get_repo('joseadp/uc-phd-josep-data')

SAT_NAME_LIST = ['cppcheck', 'flawfinder']
# Maps the SAT name identifier used in the result files to a full version of the SAT name.
# This last name is what's stored in the database.
FULL_SAT_NAME = {
	'cppcheck': 'Cppcheck',
	'flawfinder': 'Flawfinder',
}

mozilla_file_list = []
for sat_name in SAT_NAME_LIST:
	sat_files = repository.get_contents(f'mozilla/{sat_name}')
	mozilla_file_list.extend(sat_files)

zip_file_list = []
ZIPPED_CSV_REGEX = re.compile(r'.*\.csv\.zip', re.IGNORECASE)

debug_zip_file_counter = {sat_name: 0 for sat_name in SAT_NAME_LIST}
DEBUG_MAX_FILES_PER_SAT = 15

# Traverse the repository and find every file recursively.
while mozilla_file_list:
	
	file = mozilla_file_list.pop(0)

	if file.type == 'dir':
		directory_files = repository.get_contents(file.path)
		mozilla_file_list.extend(directory_files)

	elif ZIPPED_CSV_REGEX.match(file.name):

		should_add_file = True

		# If we're in debug mode, only add a certain number of files for each SAT.
		# Otherwise, add all of them.
		if DEBUG_MODE:
			for sat_name in debug_zip_file_counter:
				if file.name.startswith(sat_name):

					debug_zip_file_counter[sat_name] += 1
					if debug_zip_file_counter[sat_name] > DEBUG_MAX_FILES_PER_SAT:
						should_add_file = False
					break

		if should_add_file:
			zip_file_list.append(file)

print()

# --------------------------------------------------

SAT_RESULTS_DIRCTORY = 'sat-results'
os.makedirs(SAT_RESULTS_DIRCTORY, exist_ok=True)

CWE_REGEX = re.compile(r'CWE-(\d+)', re.IGNORECASE)

for i, file in enumerate(zip_file_list):

	print(f'Adding the results file {i+1} of {len(zip_file_list)}...')

	zip_file_path = os.path.join(SAT_RESULTS_DIRCTORY, file.name)
	
	print(f'- Extracting the archive "{zip_file_path}"...')

	with open(zip_file_path, "wb") as zip_file:
		zip_data = base64.b64decode(file.content)
		zip_file.write(zip_data)

	with zipfile.ZipFile(zip_file_path, 'r') as zip_file:
		filenames_in_zip = zip_file.namelist()
		zip_file.extractall(SAT_RESULTS_DIRCTORY)

	csv_file_path = os.path.join(SAT_RESULTS_DIRCTORY, filenames_in_zip[0])

	print(f'- Processing the CSV file "{csv_file_path}"...')

	# Parse key properties from the filename.
	# Filename structure: "[SAT]-[Random Number]-[Hash Commit]{-1}.csv"
	# Where this last '-1' represents the file occurence ('before' if it
	# exists, or 'after' if it doesn't).
	#
	# For example:
	# - "cppcheck-1-f40f923a0a09ab1d0e28a308364a924893c5fd02.csv"
	# - "flawfinder-100-00bb6d99a7c0b6f6e4402ccbd86ef318ed255646-1.csv"
	filename = os.path.basename(csv_file_path).rsplit('.', 1)[0]
	filename_parts = filename.split('-', 3)
	
	sat_name = FULL_SAT_NAME[ filename_parts[0] ]
	file_commit = filename_parts[2]
	file_occurrence = 'before' if len(filename_parts) > 3 else 'after' 

	# Automatically add any new SATs.
	try:
		cursor.execute(	'''
							INSERT IGNORE INTO sat (SAT_NAME)
							VALUES (%s);
						''',
						(sat_name,))

		connection.commit()
	except mysql.connector.Error as error:
		error_string = repr(error)
		print(f'- Failed to insert the SAT {sat_name} with the error: {error_string}')
		sat_name = None

	# Removes the project's root directory from a file path. If this base directory does
	# not exist, then the file path is not changed.
	#
	# For example, using 'gecko-dev/' as the 'base_directory':
	# - "/opt/gecko-dev/accessible/src/atk/nsAccessibleText.h:123" -> "accessible/src/atk/nsAccessibleText.h:123"
	# - "/opt/josep/gecko-dev/cck/muc/dialshr.cpp" -> "cck/muc/dialshr.cpp"
	def remove_base_directories_from_file_path(file_path, base_directory):

		if base_directory in file_path:
			file_path = file_path.split(base_directory, 1)[1]

		return file_path

	# Process each type of SAT output.
	if sat_name == 'Cppcheck':

		# The CSV files generated by Cppcheck don't quote values with commas correctly.
		# This means that pd.read_csv() would fail because some lines have more columns
		# than others. We'll read each line ourselves and interpret anything after the
		# fourth column as being part of the 'message' column.
		dictionary_list = []
		with open(csv_file_path, 'r') as csv_file:
			for line in csv_file:

				filename_loc, severity, id, message = line.split(',', 3)
				dictionary_list.append({'filename-loc': filename_loc,
										'severity': severity,
										'id': id,
										'message': message})

		results = pd.DataFrame.from_dict(dictionary_list)

		# Replace any N/A values with None.
		results = results.replace({np.nan: None})

		# For testing purposes: only insert some alerts.
		if DEBUG_MODE:
			results = results[::5]

		print(f'- Adding {len(results)} {sat_name} ({file_occurrence}) results from the CSV file...')

		for index, row in results.iterrows():

			filename_loc = row['filename-loc']
			category = row['severity']
			rule_name = row['id']
			message = row['message']			

			file_path, line = filename_loc.split(':', 1)
			file_path = remove_base_directories_from_file_path(file_path, 'gecko-dev/')

			# There's currently no CWE column in the Cppcheck CSV files, although it exist in the Excel spreadsheets.
			# Since this value might somehow appear in the message column (which includes everything after the fourth
			# column), we'll search the text for any CWE patterns.
			cwe_list = CWE_REGEX.findall(message)
			
			severity_level = None

			insert_rule_and_alert_into_database(cursor, index,
												sat_name, rule_name, category, cwe_list,
												severity_level, line, message,
												file_path, file_occurrence, file_commit)

	elif sat_name == 'Flawfinder':

		results = pd.read_csv(csv_file_path)

		# Remove results that don't have a rule.
		results = results.dropna(subset=['Name'])

		# Replace any N/A values with None.
		results = results.replace({np.nan: None})

		# For testing purposes: only insert some alerts.
		if DEBUG_MODE:
			results = results[::5]

		print(f'- Adding {len(results)} {sat_name} ({file_occurrence}) results from the CSV file...')

		for index, row in results.iterrows():

			file_path = row['File']
			line = row['Line']
			column = row['Column']
			severity_level = row['Level']
			category = row['Category']
			rule_name = row['Name']
			warning = row['Warning']
			suggestion = row['Suggestion']
			note = row['Note']
			cwe_list = row['CWEs']
			context = row['Context']
			context_hash = row['Fingerprint']
			
			file_path = remove_base_directories_from_file_path(file_path, 'gecko-dev/')

			# Get a list of CWEs. The following values may appear:
			# - 'CWE-676, CWE-120, CWE-20'
			# - 'CWE-362/CWE-367!'
			# - 'CWE-119!/CWE-120'
			if '/' in cwe_list:
				cwe_list = [cwe.split('-', 1)[1].rsplit('!', 1)[0] for cwe in cwe_list.split('/')]
			else:
				cwe_list = [cwe.split('-', 1)[1] for cwe in cwe_list.split(',')]

			insert_rule_and_alert_into_database(cursor, index,
												sat_name, rule_name, category, cwe_list,
												severity_level, line, warning,
												file_path, file_occurrence, file_commit)

	# If it's None, then it couldn't be added to the 'sat' table in the database and should be skipped.
	elif sat_name is not None:
		print(f'Skipping the results from the unknown SAT {sat_name}: "{csv_file_path}" ({file_occurrence}).')

	# Delete the ZIP and CSV files.
	os.remove(zip_file_path)
	os.remove(csv_file_path)
	
	print()

if not zip_file_list:
	print('No SAT result files found in the GitHub repository.')
	print()

print('Finished running.')
