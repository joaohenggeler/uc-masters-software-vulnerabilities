#!/usr/bin/env python3

"""
	This script defines a class that specifies how Propheticus should batch process the datasets generated by "build_propheticus_dataset_from_raw_dataset.py".
"""

import glob
import os
from copy import deepcopy

import propheticus.core.BatchExecution

from InstanceConfig import InstanceConfig
from modules.common import log, remove_list_duplicates

class InstanceBatchExecution(propheticus.core.BatchExecution):

	def __init__(self, context):
		super(InstanceBatchExecution, self).__init__(context)

		# self.display_visuals = False

		"""
		The GUI methods are specified in 'propheticus/core/GUI.py'.
		The data analysis techniques are specified in 'propheticus/core/DataAnalysis.py'.

		GUI Methods:

		def DataAnalysis(self, method)
		def parseCurrentConfigurationAlgorithms(self, choice=None, skip_validation=False)
		[there are others]

		DataAnalysis Methods:

		descriptiveAnalysis
		boxPlots
		barPlot
		scatterPlotMatrix
		correlationMatrixPlot
		timeSeriesStd
		timeSeries
		lineGraphsStd
		lineGraphs
		parallelCoordinates
		"""

		self.Processes = [
			{'method': 'DataAnalysis', 'arguments': ['lineGraphs']},
			{'method': 'DataAnalysis', 'arguments': ['boxPlots']},
			{'method': 'DataAnalysis', 'arguments': ['correlationMatrixPlot']},
			{'method': 'parseCurrentConfigurationAlgorithms', 'arguments': [None, True]},
		]

		"""
		The dimensionality reduction techniques are specified in 'propheticus/configs/DimensionalityReduction.py'.
		The sampling techniques are specified in 'propheticus/configs/Sampling.py'.
		The algorithms and their parameters are specified in 'propheticus/configs/Classification.py'.

		Algorithm Parameters:

		# Random Forests:

		'n_estimators': {'type': 'int', 'default': 100},
		'criterion': {'type': 'str', 'values': ['gini', 'entropy']},
		'max_depth': {'type': ['int', 'None']},
		'min_samples_split': {'type': ['int', 'float']},
		'min_samples_leaf': {'type': ['int', 'float']},
		'min_weight_fraction_leaf': {'type': 'float'},
		'max_features': {'type': ['int', 'float', 'str', 'None']},
		'max_leaf_nodes': {'type': ['int', 'None']},
		'min_impurity_decrease': {'type': 'float'},
		'min_impurity_split': {'type': 'float'},
		'bootstrap': {'type': 'bool', 'values': [True, False]},
		'oob_score': {'type': 'bool', 'values': [True, False]},
		'n_jobs': {'type': ['int', 'None'], 'default': -1},
		'random_state': {'hide': True, 'type': ['int', 'None']},
		'verbose': {'type': 'int'},
		'warm_start': {'type': 'bool', 'values': [True, False]},
		'class_weight': {'type': ['dict', 'list-dicts', 'balanced', 'None']}

		# Bagging:

		'base_estimator': {'type': ''},
		'n_estimators': {'type': '', 'default': 100},
		'max_samples': {'type': ''},
		'max_features': {'type': ''},
		'bootstrap': {'type': ''},
		'bootstrap_features': {'type': ''},
		'oob_score': {'type': ''},
		'warm_start': {'type': ''},
		'n_jobs': {'type': ''},
		'random_state': {'hide': True, 'type': ''},
		'verbose': {'type': ''}

		# XGBoost:

		'n_estimators': {'type': 'int'},
		'learning_rate': {'type': 'float'},
		'max_depth': {'type': 'int'},
		'subsample': {'type': 'float'},
		'objective': {'type': 'str'},
		'gamma': {'type': 'float'},
		'alpha': {'type': 'float'},
		'lambda': {'type': 'float'},
		'random_state': {'hide': True, 'type': ''},
		"""

		base_configuration = {}
		base_configuration['config_seed_count'] = InstanceConfig.PROPHETICUS['seed_count']
		# Deprecated (see the config): base_configuration['config_cv_fold'] = 5
		base_configuration['config_data_split_parameters'] = InstanceConfig.PROPHETICUS['data_split']
		base_configuration['config_grid_search'] = False
		base_configuration['config_binary_classification'] = False
		
		# This is only used when 'config_binary_classification' is false.
		prediction_classes = list(InstanceConfig.ClassesDescription.values())
		base_configuration['datasets_positive_classes'] = prediction_classes[1:]

		for code_unit in InstanceConfig.CODE_UNIT_LIST:

			dataset_path = os.path.join(InstanceConfig.framework_instance_data_path, fr'propheticus-dataset-{code_unit}-*')
			dataset_list = glob.glob(dataset_path)

			if not dataset_list:
				log.warning(f'Could not find any {code_unit} datasets.')
				continue

			dataset_list = [os.path.basename(path).split('.')[0] for path in dataset_list]
			dataset_list = remove_list_duplicates(dataset_list)

			log.info(f'Found the following {code_unit} datasets: {dataset_list}')
	
			for target_label in InstanceConfig.PROPHETICUS['labels']:
				
				excluded_label_list = [label for label in InstanceConfig.TARGET_LABEL_LIST if label != target_label]

				for dimensionality_reduction in InstanceConfig.PROPHETICUS['dimensionality_reduction']:
					
					for data_balancing in InstanceConfig.PROPHETICUS['data_balancing']:
							
						# From the original demo:
						# TODO: improve the following logic to allow passing more than one algorithm to improve performance
						# TODO: use something similar to itertools but be aware of different lenghts in configs; itertools.product stops at the minimum length
						for classification_algorithm, raw_algorithm_parameters_list in InstanceConfig.PROPHETICUS['classification_algorithms'].items():
							
							algorithm_parameters_list = []

							for raw_algorithm_parameters in raw_algorithm_parameters_list:
								
								if isinstance(raw_algorithm_parameters, dict):
									dict_list = propheticus.shared.Utils.cartesianProductDictionaryLists(**raw_algorithm_parameters)
									algorithm_parameters_list.extend(dict_list)
								else:
									algorithm_parameters_list.append(raw_algorithm_parameters)

							for algorithm_parameters in algorithm_parameters_list:
								
								configuration = deepcopy(base_configuration)

								configuration['datasets'] = dataset_list

								configuration['pre_target'] = target_label
								configuration['pre_excluded_features'] = excluded_label_list

								configuration['proc_reduce_dimensionality'] = dimensionality_reduction
								configuration['proc_balance_data'] = data_balancing

								configuration['proc_classification'] = [classification_algorithm]

								configuration['proc_classification_algorithms_parameters'] = {}
								if algorithm_parameters is not None:
									configuration['proc_classification_algorithms_parameters'] = {classification_algorithm: algorithm_parameters}
								
								log.info(f'Adding the batch configuration: {dataset_list}, {target_label}, {dimensionality_reduction}, {data_balancing}, {classification_algorithm}, {algorithm_parameters_list}')
								self.Configurations.append(configuration)

		log.info(f'Added a total of {len(self.Configurations)} batch configurations.')